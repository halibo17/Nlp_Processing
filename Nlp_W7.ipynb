{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Similarity\n",
    "Levenstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "import codecs\n",
    "nltk.data.path.append('.')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_word_list = nltk.corpus.stopwords.words('turkish')\n",
    "import re\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Part 1: Load and Preprocess Data\n",
    "\n",
    "<a name='1.1'></a>\n",
    "### Part 1.1: Load the data\n",
    "\n",
    "https://github.com/selimfirat/bilkent-turkish-writings-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('corpus/texts.csv', encoding='utf-8')\n",
    "veri = data[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_doc(single_doc):\n",
    "    # TR: Dokümandan belirlenen özel karakterleri ve sayıları at\n",
    "    # EN: Remove special characters and numbers\n",
    "    single_doc = re.sub(\"\\d+\", \"\", single_doc)\n",
    "    single_doc = re.sub(\"[0-9]\", \"\", single_doc)\n",
    "    single_doc = re.sub(\"[?!]\", \".\", single_doc)\n",
    "    single_doc = re.sub(\"[\\r\\n-]\", \"\", single_doc)\n",
    "    pattern = r\"[{}]\".format(\".,;\") \n",
    "    single_doc = re.sub(pattern, \"\", single_doc) \n",
    "    # TR: Dokümanı küçük harflere çevir\n",
    "    # EN: Convert document to lowercase\n",
    "    single_doc = single_doc.lower()\n",
    "    single_doc = single_doc.strip()\n",
    "    # TR: Dokümanı token'larına ayır\n",
    "    # EN: Tokenize documents\n",
    "    tokens = word_tokenize(single_doc)\n",
    "    # TR: Stop-word listesindeki kelimeler hariç al\n",
    "    # EN: Filter out the stop-words \n",
    "    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n",
    "    # TR: Dokümanı tekrar oluştur\n",
    "    # EN: Reconstruct the document\n",
    "   # single_doc = ' '.join(filtered_tokens)\n",
    "    return single_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-6f4c59464548>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'][i] = norm_doc(data['text'][i])\n"
     ]
    }
   ],
   "source": [
    "veri = ''\n",
    "data['text']=data['text'].apply(str)\n",
    "for i in range(len(data['text'])):\n",
    "    if data['text'][i] is not None:\n",
    "        data['text'][i] = norm_doc(data['text'][i])\n",
    "        veri = veri + data['text'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_data(data):    \n",
    "    tokenized_data = nltk.word_tokenize(data.lower())\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_veri = tokenized_data(veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tokenized_data , count_threshold = 5):\n",
    "\n",
    "    word_counts = {}\n",
    "    word_threshold_high = []\n",
    "    word_threshold_low = []\n",
    "\n",
    "    for i in range(len(tokenized_data)): \n",
    "\n",
    "        if tokenized_data[i] not in word_counts.keys(): \n",
    "            word_counts[tokenized_data[i]] = 1\n",
    "        else:\n",
    "            word_counts[tokenized_data[i]] += 1\n",
    "            \n",
    "            \n",
    "    for word, cnt in word_counts.items():\n",
    "        \n",
    "        if cnt > count_threshold:\n",
    "            word_threshold_high.append(word)\n",
    "            \n",
    "        if cnt < count_threshold:\n",
    "            word_threshold_low.append(word)\n",
    "  \n",
    "    return word_threshold_high , word_threshold_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_high, word_low = count_words(tokenized_veri , 5)\n",
    "word_l = word_low[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_similarity(word, word_high):\n",
    "    \n",
    "    high_prob = 100\n",
    "    high_prob_word = ''\n",
    "\n",
    "    for i in range(len(word_high)):\n",
    "        dist = editdistance.eval(word, word_high[i])\n",
    "        if high_prob > dist:\n",
    "            high_prob = dist\n",
    "\n",
    "            high_prob_word = word_high[i]\n",
    "            \n",
    "    return high_prob_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erdurcan kelimesinin yerine erduran kullanılabilir\n",
      "i̇kon kelimesinin yerine i̇ron kullanılabilir\n",
      "monreo kelimesinin yerine monroe kullanılabilir\n",
      "hırçınlğıyla kelimesinin yerine kırıklığıyla kullanılabilir\n",
      "hırçınlığının kelimesinin yerine kırıklığının kullanılabilir\n",
      "ızdırapla kelimesinin yerine ızdırap kullanılabilir\n",
      "notlarda kelimesinin yerine notlar kullanılabilir\n",
      "farkederek kelimesinin yerine farkeder kullanılabilir\n",
      "tanıyacağımı kelimesinin yerine tanışacağım kullanılabilir\n",
      "dökümanla kelimesinin yerine zamanla kullanılabilir\n",
      "besleyemezdim kelimesinin yerine beklenemezdi kullanılabilir\n",
      "emsalsizliği kelimesinin yerine emsalsiz kullanılabilir\n",
      "hırpalanmıştı kelimesinin yerine sıralanmış kullanılabilir\n",
      "haketmemişti kelimesinin yerine etmemişti kullanılabilir\n",
      "haketmediklerini kelimesinin yerine etmediklerini kullanılabilir\n",
      "seçmedi kelimesinin yerine geçmedi kullanılabilir\n",
      "benimsedi kelimesinin yerine benimsedim kullanılabilir\n",
      "kandırmamıştı kelimesinin yerine kalmamıştı kullanılabilir\n",
      "anlatmamıştı kelimesinin yerine anlamamıştım kullanılabilir\n",
      "arzulanmayı kelimesinin yerine arzulama kullanılabilir\n",
      "çizmişti kelimesinin yerine çizmiştir kullanılabilir\n",
      "savunmadan kelimesinin yerine savunmaya kullanılabilir\n",
      "başarabilmişti kelimesinin yerine başarabilmiştir kullanılabilir\n",
      "istediyse kelimesinin yerine isteğiyle kullanılabilir\n",
      "olabilmişti kelimesinin yerine olabilmiş kullanılabilir\n",
      "sevmeyeceklerse kelimesinin yerine sevmeyenler kullanılabilir\n",
      "kalbinizden kelimesinin yerine kalbimizden kullanılabilir\n",
      "sahiplendiğiniz kelimesinin yerine sahiplendiğimiz kullanılabilir\n",
      "sevgilerden kelimesinin yerine sevgilerde kullanılabilir\n",
      "vazgeçirmeyi kelimesinin yerine vazgeçirmeye kullanılabilir\n",
      "hırpalanmak kelimesinin yerine yargılanmak kullanılabilir\n",
      "hırpalamak kelimesinin yerine parçalamak kullanılabilir\n",
      "adamsanız kelimesinin yerine ararsanız kullanılabilir\n",
      "ikonuyla kelimesinin yerine konuyla kullanılabilir\n",
      "sarışınla kelimesinin yerine sarışın kullanılabilir\n",
      "i̇stemişlerdi kelimesinin yerine istemişlerdir kullanılabilir\n",
      "olamazlardı kelimesinin yerine olamazlar kullanılabilir\n",
      "edebilmişlerdi kelimesinin yerine edebildikleri kullanılabilir\n",
      "sevdirebilirdiniz kelimesinin yerine geçirebilirsiniz kullanılabilir\n",
      "imajda kelimesinin yerine imajı kullanılabilir\n",
      "tüketmişlerdi kelimesinin yerine öğretmişlerdi kullanılabilir\n",
      "kameraları kelimesinin yerine kameralar kullanılabilir\n",
      "mümkünleşti kelimesinin yerine mümkünmüş kullanılabilir\n",
      "ızdırabın kelimesinin yerine ızdırap kullanılabilir\n",
      "farketmesek kelimesinin yerine farketmeden kullanılabilir\n",
      "imajdan kelimesinin yerine limandan kullanılabilir\n",
      "kandırmadan kelimesinin yerine kaldırmadan kullanılabilir\n",
      "kitapgalerisi kelimesinin yerine galerisi kullanılabilir\n",
      "october kelimesinin yerine otobüs kullanılabilir\n",
      "//wwwkitapgalerisicom/marilynmonroenotlar_htmlyalçın kelimesinin yerine //wwwimdbcom/title/tt/ kullanılabilir\n"
     ]
    }
   ],
   "source": [
    "similar = []\n",
    "for i in range(len(word_l)):\n",
    "    high_prob_word =  estimate_similarity(word_l[i] , word_high)\n",
    "    similar.append([word_l[i],high_prob_word])\n",
    "    print('%s kelimesinin yerine %s kullanılabilir' % (word_l[i], high_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['erdurcan', 'erduran'],\n",
       " ['i̇kon', 'i̇ron'],\n",
       " ['monreo', 'monroe'],\n",
       " ['hırçınlğıyla', 'kırıklığıyla'],\n",
       " ['hırçınlığının', 'kırıklığının'],\n",
       " ['ızdırapla', 'ızdırap'],\n",
       " ['notlarda', 'notlar'],\n",
       " ['farkederek', 'farkeder'],\n",
       " ['tanıyacağımı', 'tanışacağım'],\n",
       " ['dökümanla', 'zamanla'],\n",
       " ['besleyemezdim', 'beklenemezdi'],\n",
       " ['emsalsizliği', 'emsalsiz'],\n",
       " ['hırpalanmıştı', 'sıralanmış'],\n",
       " ['haketmemişti', 'etmemişti'],\n",
       " ['haketmediklerini', 'etmediklerini'],\n",
       " ['seçmedi', 'geçmedi'],\n",
       " ['benimsedi', 'benimsedim'],\n",
       " ['kandırmamıştı', 'kalmamıştı'],\n",
       " ['anlatmamıştı', 'anlamamıştım'],\n",
       " ['arzulanmayı', 'arzulama'],\n",
       " ['çizmişti', 'çizmiştir'],\n",
       " ['savunmadan', 'savunmaya'],\n",
       " ['başarabilmişti', 'başarabilmiştir'],\n",
       " ['istediyse', 'isteğiyle'],\n",
       " ['olabilmişti', 'olabilmiş'],\n",
       " ['sevmeyeceklerse', 'sevmeyenler'],\n",
       " ['kalbinizden', 'kalbimizden'],\n",
       " ['sahiplendiğiniz', 'sahiplendiğimiz'],\n",
       " ['sevgilerden', 'sevgilerde'],\n",
       " ['vazgeçirmeyi', 'vazgeçirmeye'],\n",
       " ['hırpalanmak', 'yargılanmak'],\n",
       " ['hırpalamak', 'parçalamak'],\n",
       " ['adamsanız', 'ararsanız'],\n",
       " ['ikonuyla', 'konuyla'],\n",
       " ['sarışınla', 'sarışın'],\n",
       " ['i̇stemişlerdi', 'istemişlerdir'],\n",
       " ['olamazlardı', 'olamazlar'],\n",
       " ['edebilmişlerdi', 'edebildikleri'],\n",
       " ['sevdirebilirdiniz', 'geçirebilirsiniz'],\n",
       " ['imajda', 'imajı'],\n",
       " ['tüketmişlerdi', 'öğretmişlerdi'],\n",
       " ['kameraları', 'kameralar'],\n",
       " ['mümkünleşti', 'mümkünmüş'],\n",
       " ['ızdırabın', 'ızdırap'],\n",
       " ['farketmesek', 'farketmeden'],\n",
       " ['imajdan', 'limandan'],\n",
       " ['kandırmadan', 'kaldırmadan'],\n",
       " ['kitapgalerisi', 'galerisi'],\n",
       " ['october', 'otobüs'],\n",
       " ['//wwwkitapgalerisicom/marilynmonroenotlar_htmlyalçın',\n",
       "  '//wwwimdbcom/title/tt/']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC2-3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
